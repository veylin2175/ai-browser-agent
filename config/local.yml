app:
  env: local
  name: browser-ai-agent

llm:
  provider: mistral
  model: meta-llama/Llama-3.1-70B-Instruct
  max_tokens: 4096
  temperature: 0.05

browser:
  engine: chromium
  viewport:
    width: 1280
    height: 900
  timeout_ms: 5000

agent:
  max_steps: 50
  ask_confirmation: true
  memory:
    short_term_steps: 5
    max_page_elements: 80

logging:
  level: debug